{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework you will be performing some analysis with entity extraction. In particular, you will be looking at the Reuters corpus and trying to construct entity profiles of persons, organizations, and locations. This will require you to iterate through the documents in the Reuters corpus, parse them appropriately, extract entities, and then store the entities along with some surrounding text. Additionally, you will be looking for mechanisms to identify potential relationships between persons and locations.\n",
    "\n",
    "\n",
    "Throughout this you will need to use NLTK to access the corpus. At the same time, you will need to use an entity extraction system. You will want to use Spacy for named entity recognition.\n",
    "\n",
    "The basic idea is to build a knowledge base around the entities you will extract in the Reuters corpus. Normally, this would be a first step to trying to model such things as entity resolution across documents. You could also use this as a first step to analyzing the sentiment towards particular entities. For example, people expressing dissatistfaction at a restaurant or brand.\n",
    "\n",
    "\n",
    "Follow the below steps and read the comments carefully on the types of tasks your code will need to do.\n",
    "\n",
    "\n",
    "I would expect that some of you might be able to reuse parts of this code for your project..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1) \n",
    "Import necessary librariesÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/kristinlevine/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the corpus we work from\n",
    "\n",
    "# in order for this to work you will have to have installed NLTK \n",
    "# and also installed the reuters data\n",
    "\n",
    "# to install NLTK, pip install nltk\n",
    "\n",
    "# To install the reuters corpus following the instructions here: https://www.nltk.org/data.html\n",
    "# The easy way to install the Reuters corpus is usally:\n",
    "# import nltk\n",
    "# nltk.download('reuters')\n",
    "\n",
    "\n",
    "# This will import the Reuters corpus, assuming you have it\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will want to use Spacy as your entity recognizer\n",
    "# my suggestion would be to make sure you are using a 2.x version of Spacy\n",
    "# pip install spacy==2.3.5\n",
    "import spacy\n",
    "# note, the model load can be odd. In some instances your model might have the full name or the short name here.\n",
    "# if you run into issues here, check the spacy model page at https://spacy.io/usage/models\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "# alternatively try: \n",
    "# spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/14826\n",
      "ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPAN RIFT Mounting trade friction between the U . S . And Japan has raised fears among many of Asia ' s exporting nations that the row could inflict far - reaching economic damage , businessmen and officials said . They told Reuter correspondents in Asian capitals a U . S . Move against Japan might boost protectionist sentiment in the U . S . And lead to curbs on American imports of their products . But some exporters said that while the conflict would hurt them in the long - run , in the short - term Tokyo ' s loss might be their gain . The U . S . Has said it will impose 300 mln dlrs of tariffs on imports of Japanese electronics goods on April 17 , in retaliation for Japan ' s alleged failure to stick to a pact not to sell semiconductors on world markets at below cost . Unofficial Japanese estimates put the impact of the tariffs at 10 billion dlrs and spokesmen for major electronics firms said they would virtually halt exports of products hit by the new taxes . \" We wouldn ' t be able to do business ,\" said a spokesman for leading Japanese electronics firm Matsushita Electric Industrial Co Ltd & lt ; MC . T >. \" If the tariffs remain in place for any length of time beyond a few months it will mean the complete erosion of exports ( of goods subject to tariffs ) to the U . S .,\" said Tom Murtha , a stock analyst at the Tokyo office of broker & lt ; James Capel and Co >. In Taiwan , businessmen and officials are also worried . \" We are aware of the seriousness of the U . S . Threat against Japan because it serves as a warning to us ,\" said a senior Taiwanese trade official who asked not to be named . Taiwan had a trade trade surplus of 15 . 6 billion dlrs last year , 95 pct of it with the U . S . The surplus helped swell Taiwan ' s foreign exchange reserves to 53 billion dlrs , among the world ' s largest . \" We must quickly open our markets , remove trade barriers and cut import tariffs to allow imports of U . S . Products , if we want to defuse problems from possible U . S . Retaliation ,\" said Paul Sheen , chairman of textile exporters & lt ; Taiwan Safe Group >. A senior official of South Korea ' s trade promotion association said the trade dispute between the U . S . And Japan might also lead to pressure on South Korea , whose chief exports are similar to those of Japan . Last year South Korea had a trade surplus of 7 . 1 billion dlrs with the U . S ., Up from 4 . 9 billion dlrs in 1985 . In Malaysia , trade officers and businessmen said tough curbs against Japan might allow hard - hit producers of semiconductors in third countries to expand their sales to the U . S . In Hong Kong , where newspapers have alleged Japan has been selling below - cost semiconductors , some electronics manufacturers share that view . But other businessmen said such a short - term commercial advantage would be outweighed by further U . S . Pressure to block imports . \" That is a very short - term view ,\" said Lawrence Mills , director - general of the Federation of Hong Kong Industry . \" If the whole purpose is to prevent imports , one day it will be extended to other sources . Much more serious for Hong Kong is the disadvantage of action restraining trade ,\" he said . The U . S . Last year was Hong Kong ' s biggest export market , accounting for over 30 pct of domestically produced exports . The Australian government is awaiting the outcome of trade talks between the U . S . And Japan with interest and concern , Industry Minister John Button said in Canberra last Friday . \" This kind of deterioration in trade relations between two countries which are major trading partners of ours is a very serious matter ,\" Button said . He said Australia ' s concerns centred on coal and beef , Australia ' s two largest exports to Japan and also significant U . S . Exports to that country . Meanwhile U . S .- Japanese diplomatic manoeuvres to solve the trade stand - off continue . Japan ' s ruling Liberal Democratic Party yesterday outlined a package of economic measures to boost the Japanese economy . The measures proposed include a large supplementary budget and record public works spending in the first half of the financial year . They also call for stepped - up spending as an emergency measure to stimulate the economy despite Prime Minister Yasuhiro Nakasone ' s avowed fiscal reform program . Deputy U . S . Trade Representative Michael Smith and Makoto Kuroda , Japan ' s deputy minister of International Trade and Industry ( MITI ), are due to meet in Washington this week in an effort to end the dispute .\n"
     ]
    }
   ],
   "source": [
    "print(reuters.fileids()[0])\n",
    "#reuters.categories()\n",
    "#return raw text of reuters corpus\n",
    "def get_corpus_text():\n",
    "    return [\" \".join(reuters.words(fid)) for fid in reuters.fileids()] \n",
    "\n",
    "#Get text for first article so we can see what we are dealing with\n",
    "a = reuters.fileids()[0]\n",
    "b = get_corpus_text()[0]\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2) \n",
    "FIll in the following function to extract the entity, document id, and relevant sentence text from the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(doc_id, doc_text):\n",
    "    analyzed_doc = nlp(doc_text)\n",
    "\n",
    "    #Three dictionaries for persons, organizations, and locations found in a document.\n",
    "\n",
    "    doc_persons = {}\n",
    "    doc_organizations = {}\n",
    "    doc_locations = {}\n",
    "    \n",
    "    for entity in analyzed_doc.ents:\n",
    "        if entity.text.strip() != \"\" and entity.label_ == \"PERSON\":\n",
    "            if entity.text.strip() not in doc_persons.keys():\n",
    "                relevant_sentence = (doc_id, entity.sent.text)\n",
    "                doc_persons[entity.text.strip()] = list()\n",
    "            if entity.text.strip() in doc_persons.keys():\n",
    "                relevant_sentence = (doc_id, entity.sent.text)\n",
    "                doc_persons[entity.text.strip()].append(relevant_sentence)  \n",
    "\n",
    "    for entity in analyzed_doc.ents:\n",
    "        if entity.text.strip() != \"\" and entity.label_ == 'ORG':\n",
    "            relevant_sentence = (doc_id, entity.sent.text)\n",
    "            doc_organizations[entity.text.strip()] = relevant_sentence\n",
    "            \n",
    "    for entity in analyzed_doc.ents:\n",
    "        if entity.text.strip() != \"\" and (entity.label_ == 'LOC' or entity.label_ == \"GPE\"):\n",
    "            relevant_sentence = (doc_id, entity.sent.text)\n",
    "            doc_locations[entity.text.strip()] = relevant_sentence\n",
    "            \n",
    "            \n",
    "    return doc_persons, doc_organizations, doc_locations\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "per, org, loc = extract_entities(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Reuter': [('test/14826', 'They told Reuter correspondents in Asian capitals a U .')], 'MC': [('test/14826', '\" We wouldn \\' t be able to do business ,\" said a spokesman for leading Japanese electronics firm Matsushita Electric Industrial Co Ltd & lt ; MC .')], 'Tom Murtha': [('test/14826', 'S .,\" said Tom Murtha , a stock analyst at the Tokyo office of broker & lt ; James Capel and Co >.')], 'Paul Sheen': [('test/14826', 'Retaliation ,\" said Paul Sheen , chairman of textile exporters & lt ; Taiwan Safe Group')], 'Lawrence Mills': [('test/14826', '\" That is a very short - term view ,\" said Lawrence Mills , director - general of the Federation of Hong Kong Industry .')], 'John Button': [('test/14826', 'And Japan with interest and concern , Industry Minister John Button said in Canberra last Friday .')], 'Yasuhiro Nakasone': [('test/14826', \"They also call for stepped - up spending as an emergency measure to stimulate the economy despite Prime Minister Yasuhiro Nakasone ' s avowed fiscal reform program .\")], 'Michael Smith': [('test/14826', \"Trade Representative Michael Smith and Makoto Kuroda , Japan ' s deputy minister of International Trade and Industry ( MITI ), are due to meet in Washington this week in an effort to end the dispute .\")]}\n"
     ]
    }
   ],
   "source": [
    "print(per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persons in document: test/14826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reuter</th>\n",
       "      <td>(test/14826, They told Reuter correspondents i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC</th>\n",
       "      <td>(test/14826, \" We wouldn ' t be able to do bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom Murtha</th>\n",
       "      <td>(test/14826, S .,\" said Tom Murtha , a stock a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paul Sheen</th>\n",
       "      <td>(test/14826, Retaliation ,\" said Paul Sheen , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lawrence Mills</th>\n",
       "      <td>(test/14826, \" That is a very short - term vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John Button</th>\n",
       "      <td>(test/14826, And Japan with interest and conce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yasuhiro Nakasone</th>\n",
       "      <td>(test/14826, They also call for stepped - up s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael Smith</th>\n",
       "      <td>(test/14826, Trade Representative Michael Smit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0\n",
       "Reuter             (test/14826, They told Reuter correspondents i...\n",
       "MC                 (test/14826, \" We wouldn ' t be able to do bus...\n",
       "Tom Murtha         (test/14826, S .,\" said Tom Murtha , a stock a...\n",
       "Paul Sheen         (test/14826, Retaliation ,\" said Paul Sheen , ...\n",
       "Lawrence Mills     (test/14826, \" That is a very short - term vie...\n",
       "John Button        (test/14826, And Japan with interest and conce...\n",
       "Yasuhiro Nakasone  (test/14826, They also call for stepped - up s...\n",
       "Michael Smith      (test/14826, Trade Representative Michael Smit..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Persons in Document\n",
    "import pandas as pd\n",
    "print('Persons in document:', a)\n",
    "pd.DataFrame.from_dict(per, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizations in document: test/14833\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CPO</th>\n",
       "      <td>test/14833</td>\n",
       "      <td>Indonesian exports of CPO in calendar 1986 wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hasrul Harahap</th>\n",
       "      <td>test/14833</td>\n",
       "      <td>RISING SHARPLY Indonesia expects crude palm oi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>central bank</th>\n",
       "      <td>test/14833</td>\n",
       "      <td>Indonesian exports of CPO in calendar 1986 wer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      File                                           Sentence\n",
       "CPO             test/14833  Indonesian exports of CPO in calendar 1986 wer...\n",
       "Hasrul Harahap  test/14833  RISING SHARPLY Indonesia expects crude palm oi...\n",
       "central bank    test/14833  Indonesian exports of CPO in calendar 1986 wer..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Organizations in document\n",
    "import pandas as pd\n",
    "print('Organizations in document:', a)\n",
    "pd.DataFrame.from_dict(org, orient = 'index', columns = ['File', \"Sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations in document: test/14833\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>test/14833</td>\n",
       "      <td>Indonesia , the world ' s second largest produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malaysia</th>\n",
       "      <td>test/14833</td>\n",
       "      <td>Indonesia , the world ' s second largest produ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 File                                           Sentence\n",
       "Indonesia  test/14833  Indonesia , the world ' s second largest produ...\n",
       "Malaysia   test/14833  Indonesia , the world ' s second largest produ..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Locations in document\n",
    "import pandas as pd\n",
    "print('Locations in document:', a)\n",
    "pd.DataFrame.from_dict(loc, orient = 'index', columns = ['File', \"Sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3)\n",
    "Adjust the following code to run the document entity extraction function Also, add the entity records you are constructing to your master list of entities Note: for the full subission run across all the Reuters documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-eeaa27fd8a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcombined_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mcombined_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "num_docs = len(reuters.fileids()[0:25])\n",
    "#  this has a large number of files... \n",
    "# you might wish to limit the number of documents you use while developing your technique \n",
    "# ex. reuters.fileids()[0:25]\n",
    "\n",
    "# these two dictionaries will incorporate all the referneces to \n",
    "combined_persons = {}\n",
    "combined_organizations = {}\n",
    "combined_locations = {}\n",
    "\n",
    "# this will only iterate over the first 25 documents, for the real submission you will need to run across all documents\n",
    "for doc_id in reuters.fileids()[0:25]: \n",
    "    # this doc_text variable will give you a text version of the news article. This could be tokenized.\n",
    "    persons, organizations, locations = extract_entities(doc_id, reuters.open(doc_id).read())\n",
    "    \n",
    "    for per in persons.keys():\n",
    "        if per not in combined_persons:\n",
    "            combined_persons[per] = persons.get(per)\n",
    "        else:\n",
    "            combined_persons[per].append(persons.get(per))\n",
    "            \n",
    "    for org in organizations.keys():\n",
    "        if org not in combined_organizations:\n",
    "            combined_organizations[org] = organizations.get(org)\n",
    "    \n",
    "    for loc in locations.keys():\n",
    "        if loc not in combined_locations:\n",
    "            combined_locations[loc] = locations.get(loc)\n",
    "        else:\n",
    "            combined_locations[loc].append(locations.get(loc))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>John Button</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>The Australian government is awaiting the outc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lawrence Mills</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>\"That is a very short-term view,\" said Lawrenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael Smith</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>Deputy U.S. Trade Representative Michael Smith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paul Sheen</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>\"We must quickly open our markets, remove trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuter</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>They told Reuter correspondents in Asian capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom\\n  Murtha</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>\"If the tariffs remain in place for any length...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yasuhiro Nakasone's</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>They also call for stepped-up spending as an e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           File  \\\n",
       "John Button          test/14826   \n",
       "Lawrence Mills       test/14826   \n",
       "Michael Smith        test/14826   \n",
       "Paul Sheen           test/14826   \n",
       "Reuter               test/14826   \n",
       "Tom\\n  Murtha        test/14826   \n",
       "Yasuhiro Nakasone's  test/14826   \n",
       "\n",
       "                                                              Sentence  \n",
       "John Button          The Australian government is awaiting the outc...  \n",
       "Lawrence Mills       \"That is a very short-term view,\" said Lawrenc...  \n",
       "Michael Smith        Deputy U.S. Trade Representative Michael Smith...  \n",
       "Paul Sheen           \"We must quickly open our markets, remove trad...  \n",
       "Reuter               They told Reuter correspondents in Asian capit...  \n",
       "Tom\\n  Murtha        \"If the tariffs remain in place for any length...  \n",
       "Yasuhiro Nakasone's  They also call for stepped-up spending as an e...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combined Persons\n",
    "import pandas as pd\n",
    "person_df = pd.DataFrame.from_dict(combined_persons, orient = 'index', columns = ['File', \"Sentence\"])\n",
    "person_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Matsushita Electric\\n  Industrial Co Ltd &amp;lt;MC.T</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>\"We wouldn't be able to do business,\" said a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broker &amp;lt;James\\n  Capel and Co</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>\"If the tariffs remain in place for any length...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S. Products</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>\"We must quickly open our markets, remove trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;lt;Taiwan Safe Group</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>\"We must quickly open our markets, remove trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S. Pressure</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>But other businessmen said such\\n  a short-ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Federation of Hong Kong Industry</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>\"That is a very short-term view,\" said Lawrenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Button</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>This kind of deterioration in trade relations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberal Democratic Party</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>Japan's ruling Liberal Democratic Party yester...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Makoto\\n  Kuroda</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>Deputy U.S. Trade Representative Michael Smith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Trade and</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>Deputy U.S. Trade Representative Michael Smith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHINA DAILY SAYS</th>\n",
       "      <td>test/14828</td>\n",
       "      <td>CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the China Daily</th>\n",
       "      <td>test/14828</td>\n",
       "      <td>A survey of 19 provinces and seven cities\\n  s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Ministry of International Trade and\\n  Industry</th>\n",
       "      <td>test/14829</td>\n",
       "      <td>The Ministry of International Trade and\\n  Ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the\\n  Agency of Natural Resources and Energy</th>\n",
       "      <td>test/14829</td>\n",
       "      <td>MITI is planning to work out a revised energy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MITI</th>\n",
       "      <td>test/14829</td>\n",
       "      <td>They said MITI will also review the breakdown ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          File  \\\n",
       "Matsushita Electric\\n  Industrial Co Ltd &lt;MC.T   test/14826   \n",
       "broker &lt;James\\n  Capel and Co                    test/14826   \n",
       "U.S. Products                                       test/14826   \n",
       "&lt;Taiwan Safe Group                               test/14826   \n",
       "U.S. Pressure                                       test/14826   \n",
       "the Federation of Hong Kong Industry                test/14826   \n",
       "Button                                              test/14826   \n",
       "Liberal Democratic Party                            test/14826   \n",
       "Makoto\\n  Kuroda                                    test/14826   \n",
       "International Trade and                             test/14826   \n",
       "CHINA DAILY SAYS                                    test/14828   \n",
       "the China Daily                                     test/14828   \n",
       "The Ministry of International Trade and\\n  Indu...  test/14829   \n",
       "the\\n  Agency of Natural Resources and Energy       test/14829   \n",
       "MITI                                                test/14829   \n",
       "\n",
       "                                                                                             Sentence  \n",
       "Matsushita Electric\\n  Industrial Co Ltd &lt;MC.T   \"We wouldn't be able to do business,\" said a s...  \n",
       "broker &lt;James\\n  Capel and Co                    \"If the tariffs remain in place for any length...  \n",
       "U.S. Products                                       \"We must quickly open our markets, remove trad...  \n",
       "&lt;Taiwan Safe Group                               \"We must quickly open our markets, remove trad...  \n",
       "U.S. Pressure                                       But other businessmen said such\\n  a short-ter...  \n",
       "the Federation of Hong Kong Industry                \"That is a very short-term view,\" said Lawrenc...  \n",
       "Button                                              This kind of deterioration in trade relations ...  \n",
       "Liberal Democratic Party                            Japan's ruling Liberal Democratic Party yester...  \n",
       "Makoto\\n  Kuroda                                    Deputy U.S. Trade Representative Michael Smith...  \n",
       "International Trade and                             Deputy U.S. Trade Representative Michael Smith...  \n",
       "CHINA DAILY SAYS                                    CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...  \n",
       "the China Daily                                     A survey of 19 provinces and seven cities\\n  s...  \n",
       "The Ministry of International Trade and\\n  Indu...  The Ministry of International Trade and\\n  Ind...  \n",
       "the\\n  Agency of Natural Resources and Energy       MITI is planning to work out a revised energy ...  \n",
       "MITI                                                They said MITI will also review the breakdown ...  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combined Organizations\n",
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(combined_organizations, orient = 'index', columns = ['File', \"Sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U.S.</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>Deputy U.S. Trade Representative Michael Smith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>Deputy U.S. Trade Representative Michael Smith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asia</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>And Japan has raised fears among many of Asia'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokyo</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>\"If the tariffs remain in place for any length...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>The surplus helped swell Taiwan's foreign exch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Korea's</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>A senior official of South Korea's trade promo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Korea</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>Last year South Korea had a trade surplus of 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malaysia</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>In Malaysia, trade officers and businessmen sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hong Kong</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>Much more serious for Hong Kong\\n  is the disa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hong Kong's</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>The U.S. Last year was Hong Kong's biggest exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canberra</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>The Australian government is awaiting the outc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>He said Australia's concerns centred on coal a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>Deputy U.S. Trade Representative Michael Smith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>test/14828</td>\n",
       "      <td>It also said that each year 1.575 mln tonnes, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAPAN</th>\n",
       "      <td>test/14829</td>\n",
       "      <td>JAPAN TO REVISE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File                                           Sentence\n",
       "U.S.           test/14826  Deputy U.S. Trade Representative Michael Smith...\n",
       "Japan          test/14826  Deputy U.S. Trade Representative Michael Smith...\n",
       "Asia           test/14826  And Japan has raised fears among many of Asia'...\n",
       "Tokyo          test/14826  \"If the tariffs remain in place for any length...\n",
       "Taiwan         test/14826  The surplus helped swell Taiwan's foreign exch...\n",
       "South Korea's  test/14826  A senior official of South Korea's trade promo...\n",
       "South Korea    test/14826  Last year South Korea had a trade surplus of 7...\n",
       "Malaysia       test/14826  In Malaysia, trade officers and businessmen sa...\n",
       "Hong Kong      test/14826  Much more serious for Hong Kong\\n  is the disa...\n",
       "Hong Kong's    test/14826  The U.S. Last year was Hong Kong's biggest exp...\n",
       "Canberra       test/14826  The Australian government is awaiting the outc...\n",
       "Australia      test/14826  He said Australia's concerns centred on coal a...\n",
       "Washington     test/14826  Deputy U.S. Trade Representative Michael Smith...\n",
       "China          test/14828  It also said that each year 1.575 mln tonnes, ...\n",
       "JAPAN          test/14829                                    JAPAN TO REVISE"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combined Locations\n",
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(combined_locations, orient = 'index', columns = ['File', \"Sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4)\n",
    "Fill in the following method to look through the content of an entity dictionary to determine the most popular based on number of mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have the text associated with the entities, \n",
    "# you will want to focus on the 500 top entities in each category\n",
    "# Identify the top 500 entities by the count of their occurrences\n",
    "def find_most_popular_entities(entity_dictionary):\n",
    "    # sort through the entities in the dictionary by the number of sentences\n",
    "    \n",
    "    return list_of_dictionary_keys_with_most_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5)\n",
    "Now invoke your top entity mention finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply get the top persons and locations\n",
    "top_persons = find_most_popular_entities(combined_persons)\n",
    "top_locations = find_most_popular_entities(combined_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6) \n",
    "\n",
    "Analyze the most popular entities to determine what words they most frequently occur with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these dictionaries to store the most frequent terms associated with the entities\n",
    "person_most_popular_terms = {}\n",
    "organization_most_popular_terms = {}\n",
    "location_most_popular_terms = {}\n",
    "\n",
    "# finally, now find the most frequent tokens associated with the entities\n",
    "for person in top_persons:\n",
    "    # fill this dictionary with all the words in the context of the person entity\n",
    "    person_token_dictionary = {}\n",
    "\n",
    "# finally, now find the most frequent tokens associated with the entities\n",
    "for organization in top_organization:\n",
    "    # fill this dictionary with all the words in the context of the person entity\n",
    "    organization_token_dictionary = {}\n",
    "\n",
    "    \n",
    "    \n",
    "for location in top_locations:\n",
    "    # fill this dictionary with all the words in the context of the location entity\n",
    "    location_token_dictionary = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7)\n",
    "\n",
    "Present your results of the most popular entities and their associated terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present you results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "There are several extra credit options for this assignment.\n",
    "The first would be to determine which persons, organizations, and locations most frequently occur in the same sentences.\n",
    "Another task would be to attempt to resolve different forms of the same name for each person and location. For example, George Bush and Bush inside the same document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_persons = {}\n",
    "combined_organizations = {}\n",
    "combined_locations = {}\n",
    "\n",
    "# this will only iterate over the first 25 documents, for the real submission you will need to run across all documents\n",
    "for doc_id in reuters.fileids()[0:25]: \n",
    "    # this doc_text variable will give you a text version of the news article. This could be tokenized.\n",
    "    persons, organizations, locations = extract_entities(doc_id, reuters.open(doc_id).read())\n",
    "\n",
    "#For Persons\n",
    "    for per in persons.keys():\n",
    "        if per not in combined_persons.keys():\n",
    "            combined_persons[per] = list()\n",
    "        \n",
    "        if per in combined_persons.keys():\n",
    "            combined_persons[per].append(persons.get(per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(doc_id, doc_text):\n",
    "    analyzed_doc = nlp(doc_text)\n",
    "\n",
    "    #Three dictionaries for persons, organizations, and locations found in a document.\n",
    "\n",
    "    doc_persons = {}\n",
    "    doc_organizations = {}\n",
    "    doc_locations = {}\n",
    "    \n",
    "    for entity in analyzed_doc.ents:\n",
    "        if entity.text.strip() != \"\" and entity.label_ == \"PERSON\":\n",
    "            \n",
    "            if entity.text.strip() not in doc_persons.keys():\n",
    "                relevant_sentence = (doc_id, entity.sent.text)\n",
    "                doc_persons[entity.text.strip()] = list()\n",
    "                \n",
    "            if entity.text.strip() in doc_persons.keys():\n",
    "                relevant_sentence = (doc_id, entity.sent.text)\n",
    "                doc_persons[entity.text.strip()].append(relevant_sentence)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
